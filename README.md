# ğŸ§  Explainable AI (XAI): Combining Neural Networks and Decision Trees

This repository presents a **hybrid AI approach** for enhancing model interpretability by integrating **Neural Networks** and **Decision Trees**. The research explores how decision trees can approximate the decision-making process of neural networks, thereby **improving explainability without sacrificing accuracy**.

---

## ğŸ“Œ Table of Contents
1. [Project Overview](#-project-overview)  
2. [Repository Structure](#-repository-structure)  
3. [Data Description](#-data-description)  
4. [Methodology](#-methodology)  
5. [Usage Instructions](#-usage-instructions)  
6. [Requirements](#-requirements)  
7. [Results](#-results)  
8. [Contributing](#-contributing)  
9. [Author](#-author)  

---

## ğŸ” Project Overview

- **Goal**: Develop a hybrid model that enhances the interpretability of **neural networks** using **decision trees**.  
- **Key Idea**: Use decision trees as **surrogate models** to approximate the decision-making of a trained neural network.  
- **Dataset**: Synthetic datasets with **linear, circular, elliptical, and square decision boundaries**.  
- **Models Used**: Multi-Layer Perceptron (MLP), Decision Trees, Linear SVM, Logistic Regression with Polynomial Features.  

### ğŸ¯ Key Objectives
1. **Interpretability Enhancement**: Improve neural network explainability by integrating decision trees.  
2. **Feature Engineering**: Introduce derived features to enhance decision trees' ability to mimic neural networks.  
3. **Evaluation & Benchmarking**: Compare the hybrid approach with existing interpretability methods (e.g., SHAP, LIME).  

---

## ğŸ“‚ Repository Structure
```
ExplainableAI/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Explainable-AI-Final.ipynb  # Jupyter notebook for model training and evaluation
â”œâ”€â”€ Explainable-AI-Final.pdf        # Research paper explaining methodology and findings
â”œâ”€â”€ README.md                       # Project documentation
```

---

## ğŸ“Š Data Description

- **Dataset**: Synthetic classification datasets representing different decision boundaries.  
- **Feature Categories**:  
  - **Linear Decision Boundary**: Parallel to one axis.  
  - **Oblique Decision Boundary**: Diagonal separation between classes.  
  - **Circular Decision Boundary**: Classification based on radial distance.  
  - **Elliptical Decision Boundary**: More complex spatial decision surface.  
  - **Square Decision Boundary**: Classification based on a square decision region.  
- **Target Variable**: Binary classification (`Class 0` and `Class 1`).  

---

## âš™ï¸ Methodology

### **Data Preprocessing & Feature Engineering**
- **Synthetic Data Generation** â†’ Custom datasets with different decision boundaries.  
- **Feature Engineering** â†’ Introduce derived features (`Z`) to help decision trees approximate neural network boundaries.  

### **Machine Learning Models**
- **Neural Networks (MLP)** â†’ Train on raw features to learn decision boundaries.  
- **Decision Trees** â†’ Used as a **surrogate model** to approximate neural network decisions.  
- **Comparative Models**:  
  - **Linear SVM** â†’ Benchmark for linear decision boundaries.  
  - **Logistic Regression (Polynomial Features)** â†’ Compare against decision tree approximations.  

### **Evaluation Metrics**
- **Accuracy** â†’ Measure classification performance.  
- **Precision & Recall** â†’ Evaluate decision tree effectiveness in mimicking neural network predictions.  
- **Interpretability Score** â†’ Compare rule complexity between decision trees and SHAP/LIME.  

---

## ğŸš€ Usage Instructions

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/sanyog-chavhan/ExplainableAI.git
cd ExplainableAI
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run Jupyter Notebook**
```bash
jupyter notebook
```
- Open `notebooks/Explainable-AI-Final.ipynb`.  

### **4ï¸âƒ£ Explore Results**
- The notebook contains **model training, evaluation, and visualizations**.  
- Refer to `Explainable-AI-Final.pdf` for an in-depth research breakdown.  

---

## ğŸ“¦ Requirements

Below is a typical `requirements.txt`:

```txt
numpy
pandas
scikit-learn
matplotlib
seaborn
tensorflow
keras
jupyter
shap
lime
```

Ensure you have **Jupyter Notebook** installed to run the `.ipynb` file.

---

## ğŸ“ˆ Results

### **Model Performance Comparison**

| Model                  | Accuracy  |
|------------------------|----------|
| **Neural Network (MLP)**      | 96.72%   |
| **Decision Tree Approximation** | 92.84%   |
| **Linear SVM**         | 85.91%   |
| **Logistic Regression (Poly Features)** | 88.45%  |

### **Key Findings**
âœ… **Neural Networks are highly accurate but lack transparency**.  
âœ… **Decision Trees approximate neural network decision boundaries with 92.84% accuracy**.  
âœ… **Feature Engineering significantly improves decision tree performance**.  
âœ… **Hybrid approach balances accuracy with interpretability**.  

---

## ğŸ¤ Contributing

1. **Fork** this repo.  
2. Create a new branch:
   ```bash
   git checkout -b feature/your-feature
   ```
3. Commit your changes:
   ```bash
   git commit -m "Add new model or fix bug"
   ```
4. Push to GitHub:
   ```bash
   git push origin feature/your-feature
   ```
5. Open a **Pull Request**.

---

## ğŸ‘¨â€ğŸ’» Author

**Sanyog Chavhan**  
Student - MSc Data Science
ğŸ“© **sanyogchavhan2016@gmail.com**  

For collaborations or inquiries, feel free to reach out! ğŸš€
